{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqbXAOjYf562"
   },
   "source": [
    "Reference: https://www.kaggle.com/code/ekaterinadranitsyna/segformer-water-segmentation-pytorch/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Aob9fYyyAbuD",
    "outputId": "da68dca3-23d5-47d3-c994-7d8f985a96af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy) (1.3.0)\n",
      "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sympy\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.5.1+cu121 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed sympy-1.13.3\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.9.0)\n",
      "Collecting sympy==1.13.1 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
      "Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sympy, lightning-utilities, torchmetrics\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "Successfully installed lightning-utilities-0.11.9 sympy-1.13.1 torchmetrics-1.6.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers datasets\n",
    "# !pip install --upgrade sympy\n",
    "# !pip install --upgrade datasets\n",
    "# !pip install evaluate\n",
    "# !pip install transformers\n",
    "# !pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/car/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "id2label: {0: 'Background', 1: 'Damaged'}\n",
      "label2id: {'Background': 0, 'Damaged': 1}\n",
      "Number of labels: 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n",
    "\n",
    "processor = SegformerImageProcessor()\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# 데이터 경로 설정\n",
    "train_images_dir = \"/WD/content/car_damage_data_v/train/image\"\n",
    "train_masks_dir = \"/WD/content/car_damage_data_v/masks/train\"\n",
    "\n",
    "val_images_dir = \"/WD/content/car_damage_data_v/valid/image\"\n",
    "val_masks_dir = \"/WD/content/car_damage_data_v/masks/valid\"\n",
    "\n",
    "# 배경 클래스 포함\n",
    "label_mapping = {'Background': 0, 'Damaged': 1}\n",
    "\n",
    "# id2label 및 label2id 생성\n",
    "id2label = {v: k for k, v in label_mapping.items()}  # ID -> Label\n",
    "label2id = {k: v for k, v in label_mapping.items()}  # Label -> ID\n",
    "\n",
    "# 출력 확인\n",
    "print(\"id2label:\", id2label)\n",
    "print(\"label2id:\", label2id)\n",
    "\n",
    "# 라벨 개수\n",
    "num_labels = len(id2label)\n",
    "print(\"Number of labels:\", num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ff8116cf52ba45299c1b62b7220d5ea1",
      "35fa7f2995c843b493ee30221444c469",
      "36074d11187f480d91374bd5909e6abf",
      "ca5a7ed3e4d24c36bffcc91a14eca94f",
      "802bc2f9cbfa47cf92c2d8beb847a3b0",
      "8df03259160442a3881a03256628070b",
      "4108278ecc0949039bf2ad2a07e818c5",
      "f090f09aa60944258733faa9b920972d",
      "7e8e8663c06f401abf70760c1fa3f658",
      "88a7668077984e799f6b82e77ff94b24",
      "edf5dd947bae4bc5967074996cfa62b3",
      "9110a3a1eae54e36a83a9fa575ef160b",
      "154b195e88114d699a554b9907f449e4",
      "8f71ef865ae3418fb380da4f828ab4e1",
      "7769650ce0114b9f908253017cfdb897",
      "e85429c00e1148edbee139a34d11ef0f",
      "8e972b8a74c74c01abc26ee061e71290",
      "3c2c9dd3631244ab9a271a64e81568eb",
      "4ea31177b1f74daeba95a68e860c3180",
      "665211f882de423ca7dc4ba53fd89c6d",
      "32684a8be7d841efa056f8e54f2fa85f",
      "980e4f7edd9b496a9e4c393867fb4b3c",
      "ed44b86dcdd649abb088c12310e925b4",
      "4a4e9637ac124b23be83082c4ef5f1ce",
      "639e8c2323974b39898a9bb225f33516",
      "82f0bbb4e695440a88cf3ac11074157d",
      "44a1ab5f4a114f42943e65c75bcf4436",
      "50a8cd8bc87c48bfae3d5b6236d03daf",
      "5e2c5cf3736245649a2d0bc06be63607",
      "a942eea34c2948e19e4c338fdb06f652",
      "b533220ff7b44898ae583fa70e8a035a",
      "b2fc32c3ccf142048dd1116980d1ac2b",
      "0a456466197544ed9cb71bbe78763de1"
     ]
    },
    "id": "cHgccIeYevic",
    "outputId": "7e6c0737-dda6-4d05-9e57-17f03e895f3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b3 and are newly initialized: ['decode_head.batch_norm.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.running_var', 'decode_head.batch_norm.weight', 'decode_head.classifier.bias', 'decode_head.classifier.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_fuse.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SegformerForSemanticSegmentation(\n",
       "  (segformer): SegformerModel(\n",
       "    (encoder): SegformerEncoder(\n",
       "      (patch_embeddings): ModuleList(\n",
       "        (0): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (block): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.003703703870996833)\n",
       "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.007407407741993666)\n",
       "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.011111111380159855)\n",
       "            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.014814815483987331)\n",
       "            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.018518518656492233)\n",
       "            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.02222222276031971)\n",
       "            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.025925926864147186)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.029629630967974663)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.03333333507180214)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.03703703731298447)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.04074074327945709)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.04444444552063942)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.048148151487112045)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.051851850003004074)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.0555555559694767)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.05925925821065903)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.06296296417713165)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.06666667014360428)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (12): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.07037036865949631)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (13): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.07407407462596893)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (14): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.07777778059244156)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (15): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.08148147910833359)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (16): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.08518518507480621)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (17): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.08888889104127884)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.09259259700775146)\n",
       "            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.0962962955236435)\n",
       "            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.10000000149011612)\n",
       "            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): ModuleList(\n",
       "        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decode_head): SegformerDecodeHead(\n",
       "    (linear_c): ModuleList(\n",
       "      (0): SegformerMLP(\n",
       "        (proj): Linear(in_features=64, out_features=768, bias=True)\n",
       "      )\n",
       "      (1): SegformerMLP(\n",
       "        (proj): Linear(in_features=128, out_features=768, bias=True)\n",
       "      )\n",
       "      (2): SegformerMLP(\n",
       "        (proj): Linear(in_features=320, out_features=768, bias=True)\n",
       "      )\n",
       "      (3): SegformerMLP(\n",
       "        (proj): Linear(in_features=512, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (linear_fuse): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Conv2d(768, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "model_name = \"nvidia/mit-b3\"\n",
    "processor = SegformerImageProcessor.from_pretrained(model_name)\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels = 2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    "\n",
    ")\n",
    "\n",
    "model.to(device)  # 모델을 GPU로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "a1f2351f45d248fba58199dd39c8c5cd",
      "fe9e4ca8c5694f85a691303145afb153",
      "67235640d2c6420d9ad298c33e385e87",
      "10e05f86b27849dc8074c5fc25349552",
      "4f5474e79d07413ebcf8845feda89d9e",
      "e667c30f320e486baf10470fd48ab6a9",
      "845435d09ca14506a784c56e4ae5a9f3",
      "bb75302fc037446bb479abe520479828",
      "81b62805df294d8c9bc5b39813d54a8a",
      "ecb3297ad6754f338c2a9b8dd3122d10",
      "f38dc7f425f44db99ab0f9439af2c200",
      "1c3b93e8a78e4a7b8ac94ae30296308e",
      "969007622e424e70aaec1b9c5f240710",
      "4a57af2bb2c4454ea9cf659f2a79c479",
      "1c3ad526f29d41b3ad110a3f7ff296d8",
      "3636cb4304d441f5b659adb92e69c2cb",
      "9accc47cdcd44f75a075258fc5627790",
      "aa6807386f57472b9d5c401d987cd4c0",
      "47efafcdb9a94c72bdd77605046836aa",
      "025fc99e45774b97b82ced213c01b032",
      "3f9986d3944346699f42e676d93f0ba7",
      "daec601dd9ac4dac97c6b6b36e14cc4d"
     ]
    },
    "id": "qslBdOv9A07U",
    "outputId": "0a532560-07c8-46c5-8062-ab120b2259d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7062/7062 [04:48<00:00, 24.44 examples/s]  \n",
      "Map: 100%|██████████| 1513/1513 [00:56<00:00, 26.92 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset & Preprocessing\n",
    "\n",
    "def load_data(images_dir, masks_dir):\n",
    "    images = sorted(os.listdir(images_dir))\n",
    "    masks = sorted(os.listdir(masks_dir))\n",
    "\n",
    "    data = []\n",
    "    for img_name, mask_name in zip(images, masks):\n",
    "        image_path = os.path.join(images_dir, img_name)\n",
    "        mask_path = os.path.join(masks_dir, mask_name)\n",
    "        data.append({\"image\": image_path, \"mask\": mask_path})\n",
    "    return data\n",
    "\n",
    "train_data = load_data(train_images_dir, train_masks_dir)\n",
    "val_data = load_data(val_images_dir, val_masks_dir)\n",
    "\n",
    "# 데이터셋 준비\n",
    "def preprocess(example):\n",
    "    image = Image.open(example[\"image\"]).convert(\"RGB\").resize((512, 512))  # 512x512로 축소\n",
    "    mask = Image.open(example[\"mask\"]).resize((512, 512))\n",
    "    encoding = processor(image, mask, return_tensors=\"pt\")\n",
    "    encoding = {k: v.squeeze(0).to(device) for k, v in encoding.items()}\n",
    "    return encoding\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_list(train_data).map(preprocess)\n",
    "val_dataset = Dataset.from_list(val_data).map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# 데이터 처리\n",
    "train_dataset.set_format(type='torch', columns=['pixel_values', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['pixel_values', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b0cf038df14447e9b795cbc2fb7034e6",
      "1bf83befc0a04dcb82df380df5daaf32",
      "5d21ccdfc06d43bfb9f849edc5124574",
      "b377c18083674d8f867508e2e15f3206",
      "2c3b7eeb87de4bf594acd1869a55ed99",
      "28beca68a34c4394836566f6329ce3e7",
      "ba3c19d44c60496da0796b5ed6a94ecd",
      "6b8b7cf9d9674a538bf7b7f2e501b9a9",
      "4e581a709f8b4bf29d0b84f5b13efa06",
      "222c73e3477247a2b45b25b39e40393f",
      "f13320761ce04d88b2a42d3b26011850"
     ]
    },
    "id": "UQ3ROIsbfNMZ",
    "outputId": "e934d3fc-6eed-485f-9270-c46fa27c8e5f"
   },
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "import torch\n",
    "from torch import nn\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"mean_iou\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "  with torch.no_grad():\n",
    "    logits, labels = eval_pred\n",
    "    logits_tensor = torch.from_numpy(logits)\n",
    "    # scale the logits to the size of the label\n",
    "    logits_tensor = nn.functional.interpolate(\n",
    "        logits_tensor,\n",
    "        size=labels.shape[-2:],\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    ).argmax(dim=1)\n",
    "\n",
    "    pred_labels = logits_tensor.detach().cpu().numpy()\n",
    "    metrics = metric.compute(\n",
    "        predictions=pred_labels,\n",
    "        references=labels,\n",
    "        num_labels=len(id2label),\n",
    "        ignore_index = None,\n",
    "        reduce_labels=processor.do_reduce_labels,\n",
    "    )\n",
    "\n",
    "    # add per category metrics as individual key-value pairs\n",
    "    per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n",
    "    per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
    "\n",
    "    metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n",
    "    metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        \"\"\"\n",
    "        Focal Loss를 초기화합니다.\n",
    "        :param alpha: 클래스 가중치 (default = 0.25)\n",
    "        :param gamma: 포커스 파라미터 (default = 2.0)\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        \"\"\"\n",
    "        Focal Loss 계산\n",
    "        :param outputs: 모델 출력 logits (batch_size, num_classes, height, width)\n",
    "        :param targets: 타겟 라벨 (batch_size, height, width)\n",
    "        \"\"\"\n",
    "        # CrossEntropyLoss 계산\n",
    "        ce_loss = self.ce_loss(outputs, targets)\n",
    "\n",
    "        # Probabilities\n",
    "        pt = torch.exp(-ce_loss)  # 예측된 확률값\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import Trainer, TrainingArguments, SegformerForSemanticSegmentation\n",
    "from datasets import load_dataset\n",
    "\n",
    "# IoU Loss 정의\n",
    "class IoULoss(nn.Module):\n",
    "    def forward(self, outputs, targets):\n",
    "        smooth = 1.0\n",
    "        outputs = torch.sigmoid(outputs)  # Sigmoid 활성화 함수\n",
    "        intersection = (outputs * targets).sum()\n",
    "        total = (outputs + targets).sum()\n",
    "        union = total - intersection\n",
    "        iou = (intersection + smooth) / (union + smooth)\n",
    "        return 1 - iou  # IoU를 Loss로 변환\n",
    "\n",
    "# Dice Loss 정의\n",
    "class DiceLoss(nn.Module):\n",
    "    def forward(self, outputs, targets):\n",
    "        smooth = 1.0\n",
    "        outputs = torch.sigmoid(outputs)  # Sigmoid 활성화 함수\n",
    "        intersection = (outputs * targets).sum()\n",
    "        dice = (2. * intersection + smooth) / (outputs.sum() + targets.sum() + smooth)\n",
    "        return 1 - dice\n",
    "\n",
    "# IoU Loss와 Dice Loss를 조합\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, weight_iou=0.7, weight_dice=0.3):\n",
    "        super().__init__()\n",
    "        self.iou_loss = IoULoss()\n",
    "        self.dice_loss = DiceLoss()\n",
    "        self.weight_iou = weight_iou\n",
    "        self.weight_dice = weight_dice\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        iou_loss = self.iou_loss(outputs, targets)\n",
    "        dice_loss = self.dice_loss(outputs, targets)\n",
    "        return self.weight_iou * iou_loss + self.weight_dice * dice_loss\n",
    "    \n",
    "class CombinedLoss_three(nn.Module):\n",
    "    def __init__(self, weight_ce=0.5, weight_iou=0.3, weight_dice=0.2):\n",
    "        super().__init__()\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.iou_loss = IoULoss()\n",
    "        self.dice_loss = DiceLoss()\n",
    "        self.weight_ce = weight_ce\n",
    "        self.weight_iou = weight_iou\n",
    "        self.weight_dice = weight_dice\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        # CrossEntropyLoss 계산\n",
    "        ce_loss = self.ce_loss(outputs, targets)\n",
    "        # IoU와 Dice Loss 계산 (타겟 차원 맞춤 필요)\n",
    "        targets_one_hot = F.one_hot(targets, num_classes=outputs.shape[1]).permute(0, 3, 1, 2).float()\n",
    "        iou_loss = self.iou_loss(outputs, targets_one_hot)\n",
    "        dice_loss = self.dice_loss(outputs, targets_one_hot)\n",
    "        # 손실 조합\n",
    "        return self.weight_ce * ce_loss + self.weight_iou * iou_loss + self.weight_dice * dice_loss\n",
    "\n",
    "\n",
    "# CombinedLoss 정의\n",
    "loss_fn = CombinedLoss(weight_iou=0.7, weight_dice=0.3)\n",
    "loss_three = CombinedLoss_three(weight_ce=0.5, weight_iou=0.3, weight_dice=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1766/1766 [06:57<00:00,  4.23it/s, Batch Loss=0.663, Batch mIoU=0.76] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Average Training Loss: 0.8768, Average Training mIoU: 0.5337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 379/379 [00:56<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Average Validation Loss: 0.8786, Average Validation mIoU: 0.5788\n",
      "New best model saved with mIoU: 0.5788\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1766/1766 [06:42<00:00,  4.38it/s, Batch Loss=0.875, Batch mIoU=0.718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Average Training Loss: 0.8736, Average Training mIoU: 0.5875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 379/379 [00:58<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Average Validation Loss: 0.8761, Average Validation mIoU: 0.6177\n",
      "New best model saved with mIoU: 0.6177\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1766/1766 [06:40<00:00,  4.41it/s, Batch Loss=0.957, Batch mIoU=0.505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Average Training Loss: 0.8717, Average Training mIoU: 0.6165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 379/379 [00:53<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Average Validation Loss: 0.8768, Average Validation mIoU: 0.6257\n",
      "New best model saved with mIoU: 0.6257\n"
     ]
    }
   ],
   "source": [
    "# 실행은 되지만 iou값이 엄청 안좋음\n",
    "# \n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import evaluate\n",
    "import logging\n",
    "\n",
    "# 로그 설정\n",
    "log_file = \"training_log.txt\"\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 3\n",
    "best_val_iou = 0.0  # Best Validation IoU 초기값\n",
    "best_model_path = \"./best_model_new_loss_n_func.pth\"\n",
    "learning_rate = 5e-5\n",
    "batch_size = 4  # 배치 크기 설정\n",
    "\n",
    "# Optimizer와 Scheduler 초기화\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)  # 5 에포크마다 lr 감소\n",
    "\n",
    "# Loss 정의\n",
    "segmentation_loss = CombinedLoss(weight_iou=0.9, weight_dice=0.1)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    logging.info(f\"Epoch {epoch + 1}/{num_epochs} started\")\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    train_loss = 0\n",
    "    train_iou = 0\n",
    "\n",
    "    # Training 단계\n",
    "    model.train()\n",
    "    train_progress_bar = tqdm(train_dataloader, desc=\"Training\", leave=True)\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_progress_bar):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 데이터 준비\n",
    "        inputs = batch[\"pixel_values\"].to(device)\n",
    "        targets = batch[\"labels\"].to(device)\n",
    "\n",
    "        # 모델 출력\n",
    "        outputs = model(pixel_values=inputs)\n",
    "        logits = outputs.logits  # (batch_size, num_classes, height, width)\n",
    "\n",
    "        # 레이블 크기 조정\n",
    "        output_size = logits.shape[-2:]  # (height, width)\n",
    "        resized_targets = F.interpolate(\n",
    "            targets.unsqueeze(1).float(),\n",
    "            size=output_size,\n",
    "            mode=\"nearest\"\n",
    "        ).squeeze(1).long()  # Resized targets to (batch_size, height, width)\n",
    "\n",
    "        # 1. outputs에 sigmoid 적용 및 특정 클래스 이진화\n",
    "        probabilities = torch.sigmoid(logits)  # (batch_size, num_classes, height, width)\n",
    "        binary_outputs = probabilities[:, 1, :, :]  # 클래스 1의 채널 선택 (batch_size, height, width)\n",
    "\n",
    "        # 2. targets 이진화 (클래스 1인 픽셀만 1로 변환)\n",
    "        binary_targets = (resized_targets == 1).float()  # (batch_size, height, width)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = segmentation_loss(binary_outputs, binary_targets)  # CombinedLoss 사용\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # IoU 계산\n",
    "        preds = (binary_outputs > 0.5).float()  # Thresholding\n",
    "        iou = metric.compute(\n",
    "            predictions=preds.detach().cpu().numpy(),\n",
    "            references=binary_targets.detach().cpu().numpy(),\n",
    "            num_labels=2,\n",
    "            ignore_index=None\n",
    "        )[\"mean_iou\"]\n",
    "\n",
    "        # 손실 및 IoU 누적\n",
    "        train_loss += loss.item()\n",
    "        train_iou += iou\n",
    "\n",
    "        # 로그 파일 기록 (배치 단위)\n",
    "        logging.info(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}, Training Loss: {loss.item():.4f}, Training mIoU: {iou:.4f}\")\n",
    "\n",
    "        train_progress_bar.set_postfix({\"Batch Loss\": loss.item(), \"Batch mIoU\": iou})\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    avg_train_iou = train_iou / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {avg_train_loss:.4f}, Average Training mIoU: {avg_train_iou:.4f}\")\n",
    "\n",
    "    # 로그 파일 기록 (Training 에포크 단위)\n",
    "    logging.info(f\"Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {avg_train_loss:.4f}, Average Training mIoU: {avg_train_iou:.4f}\")\n",
    "\n",
    "    # Validation 단계\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_iou = 0\n",
    "    val_progress_bar = tqdm(val_dataloader, desc=\"Validation\", leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_progress_bar):\n",
    "            # 데이터 준비\n",
    "            inputs = batch[\"pixel_values\"].to(device)\n",
    "            targets = batch[\"labels\"].to(device)\n",
    "\n",
    "            # 모델 출력\n",
    "            outputs = model(pixel_values=inputs)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # 레이블 크기 조정\n",
    "            resized_targets = F.interpolate(\n",
    "                targets.unsqueeze(1).float(),\n",
    "                size=logits.shape[-2:],\n",
    "                mode=\"nearest\"\n",
    "            ).squeeze(1).long()\n",
    "\n",
    "            # 1. outputs에 sigmoid 적용 및 특정 클래스 이진화\n",
    "            probabilities = torch.sigmoid(logits)\n",
    "            binary_outputs = probabilities[:, 1, :, :]  # 클래스 1의 채널 선택\n",
    "\n",
    "            # 2. targets 이진화\n",
    "            binary_targets = (resized_targets == 1).float()\n",
    "\n",
    "            # 손실 계산\n",
    "            loss = segmentation_loss(binary_outputs, binary_targets)\n",
    "\n",
    "            # IoU 계산\n",
    "            preds = (binary_outputs > 0.5).float()\n",
    "            iou = metric.compute(\n",
    "                predictions=preds.detach().cpu().numpy(),\n",
    "                references=binary_targets.detach().cpu().numpy(),\n",
    "                num_labels=2,\n",
    "                ignore_index=None\n",
    "            )[\"mean_iou\"]\n",
    "\n",
    "            # 손실 및 IoU 누적\n",
    "            val_loss += loss.item()\n",
    "            val_iou += iou\n",
    "\n",
    "            # 로그 파일 기록 (Validation 배치 단위)\n",
    "            logging.info(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}, Validation Loss: {loss.item():.4f}, Validation mIoU: {iou:.4f}\")\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    avg_val_iou = val_iou / len(val_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Validation Loss: {avg_val_loss:.4f}, Average Validation mIoU: {avg_val_iou:.4f}\")\n",
    "\n",
    "    # 로그 파일 기록 (Validation 에포크 단위)\n",
    "    logging.info(f\"Epoch {epoch + 1}/{num_epochs}, Average Validation Loss: {avg_val_loss:.4f}, Average Validation mIoU: {avg_val_iou:.4f}\")\n",
    "\n",
    "    # 가장 좋은 IoU 모델 저장\n",
    "    if avg_val_iou > best_val_iou:\n",
    "        best_val_iou = avg_val_iou\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"New best model saved with mIoU: {best_val_iou:.4f}\")\n",
    "        logging.info(f\"New best model saved with mIoU: {best_val_iou:.4f}\")\n",
    "\n",
    "    # Scheduler step\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1514 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1514/1514 [00:59<00:00, 25.53 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Test dataset\n",
    "test_images_dir = '/WD/content/car_damage_data_v/test/image'\n",
    "test_masks_dir = '/WD/content/car_damage_data_v/masks/test'\n",
    "test_data = load_data(test_images_dir, test_masks_dir)\n",
    "test_dataset = Dataset.from_list(test_data).map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "test_dataset.set_format(type='torch', columns=['pixel_values', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1766 [00:00<?, ?it/s]/root/anaconda3/envs/car/lib/python3.12/site-packages/datasets/features/image.py:348: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "Training: 100%|██████████| 1766/1766 [06:35<00:00,  4.46it/s, Batch Loss=0.0395, Batch mIoU=0.782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Average Training Loss: 0.1566, Average Training mIoU: 0.7061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 379/379 [00:53<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Average Validation Loss: 0.1745, Average Validation mIoU: 0.6988\n",
      "New best model saved with mIoU: 0.6988\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1766/1766 [06:35<00:00,  4.46it/s, Batch Loss=0.0868, Batch mIoU=0.741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Average Training Loss: 0.1202, Average Training mIoU: 0.7377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 379/379 [00:56<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Average Validation Loss: 0.1691, Average Validation mIoU: 0.6981\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1766/1766 [06:29<00:00,  4.53it/s, Batch Loss=0.0897, Batch mIoU=0.858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Average Training Loss: 0.1067, Average Training mIoU: 0.7574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 379/379 [00:52<00:00,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Average Validation Loss: 0.1707, Average Validation mIoU: 0.6935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ce + iou 9:1\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import evaluate\n",
    "import logging\n",
    "\n",
    "# 로그 설정\n",
    "log_file = \"/WD/improve/log/training_log_ce_iou.txt\"\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 3\n",
    "best_val_iou = 0.0  # Best Validation IoU 초기값\n",
    "best_model_path = \"/WD/improve/model/best_model_ce_iou.pth\"\n",
    "learning_rate = 5e-5\n",
    "batch_size = 4  # 배치 크기 설정\n",
    "\n",
    "# 손실 함수 정의\n",
    "ce_loss_fn = torch.nn.CrossEntropyLoss()  # CrossEntropy Loss\n",
    "iou_loss_fn = IoULoss()  # IoU Loss\n",
    "\n",
    "# Optimizer와 Scheduler 초기화\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    logging.info(f\"Epoch {epoch + 1}/{num_epochs} started\")\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    train_loss = 0\n",
    "    train_iou = 0\n",
    "\n",
    "    # Training 단계\n",
    "    model.train()\n",
    "    train_progress_bar = tqdm(train_dataloader, desc=\"Training\", leave=True)\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_progress_bar):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 데이터 준비\n",
    "        inputs = batch[\"pixel_values\"].to(device)\n",
    "        targets = batch[\"labels\"].to(device)\n",
    "\n",
    "        # 모델 출력\n",
    "        outputs = model(pixel_values=inputs)\n",
    "        logits = outputs.logits  # (batch_size, num_classes, height, width)\n",
    "\n",
    "        # 레이블 크기 조정\n",
    "        output_size = logits.shape[-2:]\n",
    "        resized_targets = F.interpolate(\n",
    "            targets.unsqueeze(1).float(),\n",
    "            size=output_size,\n",
    "            mode=\"nearest\"\n",
    "        ).squeeze(1).long()\n",
    "\n",
    "        # CrossEntropy Loss 계산\n",
    "        ce_loss = ce_loss_fn(logits, resized_targets)\n",
    "\n",
    "        # IoU Loss 계산\n",
    "        targets_one_hot = F.one_hot(resized_targets, num_classes=logits.shape[1]).permute(0, 3, 1, 2).float()\n",
    "        iou_loss = iou_loss_fn(logits, targets_one_hot)\n",
    "\n",
    "        # 손실 조합\n",
    "        total_loss = 0.9 * ce_loss + 0.1 * iou_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # IoU 계산\n",
    "        preds = logits.argmax(dim=1)\n",
    "        iou = metric.compute(\n",
    "            predictions=preds.detach().cpu().numpy(),\n",
    "            references=resized_targets.detach().cpu().numpy(),\n",
    "            num_labels=2,\n",
    "            ignore_index=None\n",
    "        )[\"mean_iou\"]\n",
    "\n",
    "        # 손실 및 IoU 누적\n",
    "        train_loss += total_loss.item()\n",
    "        train_iou += iou\n",
    "\n",
    "        train_progress_bar.set_postfix({\"Batch Loss\": total_loss.item(), \"Batch mIoU\": iou})\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    avg_train_iou = train_iou / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {avg_train_loss:.4f}, Average Training mIoU: {avg_train_iou:.4f}\")\n",
    "\n",
    "    logging.info(f\"Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {avg_train_loss:.4f}, Average Training mIoU: {avg_train_iou:.4f}\")\n",
    "\n",
    "    # Validation 단계\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_iou = 0\n",
    "    val_progress_bar = tqdm(val_dataloader, desc=\"Validation\", leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_progress_bar):\n",
    "            # 데이터 준비\n",
    "            inputs = batch[\"pixel_values\"].to(device)\n",
    "            targets = batch[\"labels\"].to(device)\n",
    "\n",
    "            # 모델 출력\n",
    "            outputs = model(pixel_values=inputs)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # 레이블 크기 조정\n",
    "            resized_targets = F.interpolate(\n",
    "                targets.unsqueeze(1).float(),\n",
    "                size=logits.shape[-2:],\n",
    "                mode=\"nearest\"\n",
    "            ).squeeze(1).long()\n",
    "\n",
    "            # CrossEntropy Loss 계산\n",
    "            ce_loss = ce_loss_fn(logits, resized_targets)\n",
    "\n",
    "            # IoU Loss 계산\n",
    "            targets_one_hot = F.one_hot(resized_targets, num_classes=logits.shape[1]).permute(0, 3, 1, 2).float()\n",
    "            iou_loss = iou_loss_fn(logits, targets_one_hot)\n",
    "\n",
    "            # 손실 조합\n",
    "            total_loss = 0.5 * ce_loss + 0.5 * iou_loss\n",
    "\n",
    "            # IoU 계산\n",
    "            preds = logits.argmax(dim=1)\n",
    "            iou = metric.compute(\n",
    "                predictions=preds.detach().cpu().numpy(),\n",
    "                references=resized_targets.detach().cpu().numpy(),\n",
    "                num_labels=2,\n",
    "                ignore_index=None\n",
    "            )[\"mean_iou\"]\n",
    "\n",
    "            # 손실 및 IoU 누적\n",
    "            val_loss += total_loss.item()\n",
    "            val_iou += iou\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    avg_val_iou = val_iou / len(val_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Validation Loss: {avg_val_loss:.4f}, Average Validation mIoU: {avg_val_iou:.4f}\")\n",
    "\n",
    "    logging.info(f\"Epoch {epoch + 1}/{num_epochs}, Average Validation Loss: {avg_val_loss:.4f}, Average Validation mIoU: {avg_val_iou:.4f}\")\n",
    "\n",
    "    # 가장 좋은 IoU 모델 저장\n",
    "    if avg_val_iou > best_val_iou:\n",
    "        best_val_iou = avg_val_iou\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"New best model saved with mIoU: {best_val_iou:.4f}\")\n",
    "        logging.info(f\"New best model saved with mIoU: {best_val_iou:.4f}\")\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### focal loss 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1766 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1766/1766 [06:44<00:00,  4.36it/s, Batch Loss=0.017, Batch mIoU=0.904] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Average Training Loss: 0.0923, Average Training mIoU: 0.6326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 379/379 [00:54<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Average Validation Loss: 0.0788, Average Validation mIoU: 0.6109\n",
      "New best model saved with mIoU: 0.6109\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|███▍      | 605/1766 [02:17<04:24,  4.39it/s, Batch Loss=0.0798, Batch mIoU=0.671]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# 손실 조합\u001b[39;00m\n\u001b[1;32m     64\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.6\u001b[39m \u001b[38;5;241m*\u001b[39m focal_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.4\u001b[39m \u001b[38;5;241m*\u001b[39m iou_loss\n\u001b[0;32m---> 65\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# IoU 계산\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/car/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/car/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/car/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import evaluate\n",
    "import logging\n",
    "\n",
    "# 로그 설정\n",
    "log_file = \"/WD/improve/log/training_log_focal_iou4.txt\"\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 3\n",
    "best_val_iou = 0.0  # Best Validation IoU 초기값\n",
    "best_model_path = \"/WD/improve/model/best_model_focal_iou4.pth\"\n",
    "learning_rate = 5e-5\n",
    "batch_size = 4  # 배치 크기 설정\n",
    "\n",
    "# 손실 함수 정의\n",
    "focal_loss_fn = FocalLoss(alpha=0.15, gamma=2.5)  # Focal Loss\n",
    "iou_loss_fn = IoULoss()  # IoU Loss\n",
    "\n",
    "# Optimizer와 Scheduler 초기화\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    logging.info(f\"Epoch {epoch + 1}/{num_epochs} started\")\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    train_loss = 0\n",
    "    train_iou = 0\n",
    "\n",
    "    # Training 단계\n",
    "    model.train()\n",
    "    train_progress_bar = tqdm(train_dataloader, desc=\"Training\", leave=True)\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_progress_bar):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 데이터 준비\n",
    "        inputs = batch[\"pixel_values\"].to(device)\n",
    "        targets = batch[\"labels\"].to(device)\n",
    "\n",
    "        # 모델 출력\n",
    "        outputs = model(pixel_values=inputs)\n",
    "        logits = outputs.logits  # (batch_size, num_classes, height, width)\n",
    "\n",
    "        # 레이블 크기 조정\n",
    "        output_size = logits.shape[-2:]\n",
    "        resized_targets = F.interpolate(\n",
    "            targets.unsqueeze(1).float(),\n",
    "            size=output_size,\n",
    "            mode=\"nearest\"\n",
    "        ).squeeze(1).long()\n",
    "\n",
    "        # Focal Loss 계산\n",
    "        focal_loss = focal_loss_fn(logits, resized_targets)\n",
    "\n",
    "        # IoU Loss 계산\n",
    "        targets_one_hot = F.one_hot(resized_targets, num_classes=logits.shape[1]).permute(0, 3, 1, 2).float()\n",
    "        iou_loss = iou_loss_fn(logits, targets_one_hot)\n",
    "\n",
    "        # 손실 조합\n",
    "        total_loss = 0.6 * focal_loss + 0.4 * iou_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # IoU 계산\n",
    "        preds = logits.argmax(dim=1)\n",
    "        iou = metric.compute(\n",
    "            predictions=preds.detach().cpu().numpy(),\n",
    "            references=resized_targets.detach().cpu().numpy(),\n",
    "            num_labels=2,\n",
    "            ignore_index=None\n",
    "        )[\"mean_iou\"]\n",
    "\n",
    "        # 손실 및 IoU 누적\n",
    "        train_loss += total_loss.item()\n",
    "        train_iou += iou\n",
    "\n",
    "        train_progress_bar.set_postfix({\"Batch Loss\": total_loss.item(), \"Batch mIoU\": iou})\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    avg_train_iou = train_iou / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {avg_train_loss:.4f}, Average Training mIoU: {avg_train_iou:.4f}\")\n",
    "\n",
    "    logging.info(f\"Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {avg_train_loss:.4f}, Average Training mIoU: {avg_train_iou:.4f}\")\n",
    "\n",
    "    # Validation 단계\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_iou = 0\n",
    "    val_progress_bar = tqdm(val_dataloader, desc=\"Validation\", leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_progress_bar):\n",
    "            # 데이터 준비\n",
    "            inputs = batch[\"pixel_values\"].to(device)\n",
    "            targets = batch[\"labels\"].to(device)\n",
    "\n",
    "            # 모델 출력\n",
    "            outputs = model(pixel_values=inputs)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # 레이블 크기 조정\n",
    "            resized_targets = F.interpolate(\n",
    "                targets.unsqueeze(1).float(),\n",
    "                size=logits.shape[-2:],\n",
    "                mode=\"nearest\"\n",
    "            ).squeeze(1).long()\n",
    "\n",
    "            # Focal Loss 계산\n",
    "            focal_loss = focal_loss_fn(logits, resized_targets)\n",
    "\n",
    "            # IoU Loss 계산\n",
    "            targets_one_hot = F.one_hot(resized_targets, num_classes=logits.shape[1]).permute(0, 3, 1, 2).float()\n",
    "            iou_loss = iou_loss_fn(logits, targets_one_hot)\n",
    "\n",
    "            # 손실 조합\n",
    "            total_loss = 0.6 * focal_loss + 0.4 * iou_loss\n",
    "\n",
    "            # IoU 계산\n",
    "            preds = logits.argmax(dim=1)\n",
    "            iou = metric.compute(\n",
    "                predictions=preds.detach().cpu().numpy(),\n",
    "                references=resized_targets.detach().cpu().numpy(),\n",
    "                num_labels=2,\n",
    "                ignore_index=None\n",
    "            )[\"mean_iou\"]\n",
    "\n",
    "            # 손실 및 IoU 누적\n",
    "            val_loss += total_loss.item()\n",
    "            val_iou += iou\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    avg_val_iou = val_iou / len(val_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Validation Loss: {avg_val_loss:.4f}, Average Validation mIoU: {avg_val_iou:.4f}\")\n",
    "\n",
    "    logging.info(f\"Epoch {epoch + 1}/{num_epochs}, Average Validation Loss: {avg_val_loss:.4f}, Average Validation mIoU: {avg_val_iou:.4f}\")\n",
    "\n",
    "    # 가장 좋은 IoU 모델 저장\n",
    "    if avg_val_iou > best_val_iou:\n",
    "        best_val_iou = avg_val_iou\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"New best model saved with mIoU: {best_val_iou:.4f}\")\n",
    "        logging.info(f\"New best model saved with mIoU: {best_val_iou:.4f}\")\n",
    "\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 19/1766 [00:04<07:07,  4.08it/s, Batch Loss=0.034, Batch mIoU=0.87]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 72\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# IoU 계산\u001b[39;00m\n\u001b[1;32m     70\u001b[0m preds \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [batch_size, height, width]\u001b[39;00m\n\u001b[1;32m     71\u001b[0m iou \u001b[38;5;241m=\u001b[39m metric\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[0;32m---> 72\u001b[0m     predictions\u001b[38;5;241m=\u001b[39m\u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m     73\u001b[0m     references\u001b[38;5;241m=\u001b[39mresized_targets\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m     74\u001b[0m     num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     75\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     76\u001b[0m )[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_iou\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# 손실 및 IoU 누적\u001b[39;00m\n\u001b[1;32m     79\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import evaluate\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 3\n",
    "best_val_iou = 0.0  # Best Validation IoU 초기값\n",
    "best_model_path = \"./original.pth\"\n",
    "learning_rate = 5e-5\n",
    "batch_size = 4  # 배치 크기 설정\n",
    "\n",
    "# 로그 파일 설정\n",
    "log_file = \"original.txt\"\n",
    "if os.path.exists(log_file):\n",
    "    os.remove(log_file)  # 이전 로그 파일 삭제\n",
    "\n",
    "def write_log(message):\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(message + \"\\n\")\n",
    "    print(message)\n",
    "\n",
    "# mIoU 메트릭 초기화\n",
    "metric = evaluate.load(\"mean_iou\")\n",
    "\n",
    "# Optimizer와 Scheduler 초기화\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)  # 5 에포크마다 lr 감소\n",
    "\n",
    "# 손실 함수 정의\n",
    "segmentation_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    write_log(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    train_loss = 0\n",
    "    train_iou = 0\n",
    "\n",
    "    # Training 단계\n",
    "    model.train()\n",
    "    train_progress_bar = tqdm(train_dataloader, desc=\"Training\", leave=True)\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_progress_bar):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 데이터 준비\n",
    "        inputs = batch[\"pixel_values\"].to(device)\n",
    "        targets = batch[\"labels\"].to(device)\n",
    "\n",
    "        # 모델 출력\n",
    "        outputs = model(pixel_values=inputs)\n",
    "        logits = outputs.logits  # (batch_size, num_classes, height, width)\n",
    "\n",
    "        # 레이블 크기 조정\n",
    "        output_size = logits.shape[-2:]  # (height, width)\n",
    "        resized_targets = F.interpolate(\n",
    "            targets.unsqueeze(1).float(),\n",
    "            size=output_size,\n",
    "            mode=\"nearest\"\n",
    "        ).squeeze(1).long()\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = segmentation_loss(logits, resized_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # IoU 계산\n",
    "        preds = logits.argmax(dim=1)  # [batch_size, height, width]\n",
    "        iou = metric.compute(\n",
    "            predictions=preds.detach().cpu().numpy(),\n",
    "            references=resized_targets.detach().cpu().numpy(),\n",
    "            num_labels=2,\n",
    "            ignore_index=None\n",
    "        )[\"mean_iou\"]\n",
    "\n",
    "        # 손실 및 IoU 누적\n",
    "        train_loss += loss.item()\n",
    "        train_iou += iou\n",
    "\n",
    "        train_progress_bar.set_postfix({\"Batch Loss\": loss.item(), \"Batch mIoU\": iou})\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    avg_train_iou = train_iou / len(train_dataloader)\n",
    "    write_log(f\"Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {avg_train_loss:.4f}, Average Training mIoU: {avg_train_iou:.4f}\")\n",
    "\n",
    "    # Scheduler step\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation 단계\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_iou = 0\n",
    "    val_progress_bar = tqdm(val_dataloader, desc=\"Validation\", leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_progress_bar):\n",
    "            # 데이터 준비\n",
    "            inputs = batch[\"pixel_values\"].to(device)\n",
    "            targets = batch[\"labels\"].to(device)\n",
    "\n",
    "            # 모델 출력\n",
    "            outputs = model(pixel_values=inputs)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # 레이블 크기 조정\n",
    "            resized_targets = F.interpolate(\n",
    "                targets.unsqueeze(1).float(),\n",
    "                size=logits.shape[-2:],\n",
    "                mode=\"nearest\"\n",
    "            ).squeeze(1).long()\n",
    "\n",
    "            # 손실 계산\n",
    "            loss = segmentation_loss(logits, resized_targets)\n",
    "\n",
    "            # IoU 계산\n",
    "            preds = logits.argmax(dim=1)\n",
    "            iou = metric.compute(\n",
    "                predictions=preds.detach().cpu().numpy(),\n",
    "                references=resized_targets.detach().cpu().numpy(),\n",
    "                num_labels=2,\n",
    "                ignore_index=None\n",
    "            )[\"mean_iou\"]\n",
    "\n",
    "            # 손실 및 IoU 누적\n",
    "            val_loss += loss.item()\n",
    "            val_iou += iou\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    avg_val_iou = val_iou / len(val_dataloader)\n",
    "    write_log(f\"Epoch {epoch + 1}/{num_epochs}, Average Validation Loss: {avg_val_loss:.4f}, Average Validation mIoU: {avg_val_iou:.4f}\")\n",
    "\n",
    "    # 가장 좋은 IoU 모델 저장\n",
    "    if avg_val_iou > best_val_iou:\n",
    "        best_val_iou = avg_val_iou\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        write_log(f\"New best model saved with mIoU: {best_val_iou:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/car/lib/python3.12/site-packages/transformers/utils/deprecation.py:165: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type'\n",
      "  return func(*args, **kwargs)\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b3 and are newly initialized: ['decode_head.batch_norm.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.running_var', 'decode_head.batch_norm.weight', 'decode_head.classifier.bias', 'decode_head.classifier.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_fuse.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_209320/4186300910.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(pth_path, map_location=device)\n",
      "Testing: 100%|██████████| 379/379 [00:53<00:00,  7.11it/s, Batch Loss=0.153, Batch mIoU=0.719] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Test Loss: 0.2307, Average Test mIoU: 0.6918\n",
      "Final Test Loss: 0.2307, Final Test mIoU: 0.6918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델 설정\n",
    "model_name = \"nvidia/mit-b3\"  # 사용한 모델 이름\n",
    "processor = SegformerImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "# IoU 메트릭\n",
    "metric = evaluate.load(\"mean_iou\")\n",
    "\n",
    "# 손실 함수\n",
    "ce_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "iou_loss_fn = IoULoss()  # IoU Loss 정의 필요\n",
    "\n",
    "# 모델 로드 함수\n",
    "def load_trained_model(pth_path, device):\n",
    "    # 모델 구조 초기화\n",
    "    model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "        model_name, num_labels=2, id2label=id2label, label2id=label2id\n",
    "    )\n",
    "    # .pth 파일의 가중치 불러오기\n",
    "    state_dict = torch.load(pth_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# 테스트 함수\n",
    "def test_model(model, test_dataloader, device):\n",
    "    test_loss = 0.0\n",
    "    test_iou = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    test_progress_bar = tqdm(test_dataloader, desc=\"Testing\", leave=True)\n",
    "    \n",
    "    with torch.no_grad():  # 그래디언트 비활성화\n",
    "        for batch in test_progress_bar:\n",
    "            # 데이터 준비\n",
    "            inputs = batch[\"pixel_values\"].to(device)  # 이미지 입력\n",
    "            targets = batch[\"labels\"].to(device)      # 라벨 입력\n",
    "            \n",
    "            # 모델 예측\n",
    "            outputs = model(pixel_values=inputs)\n",
    "            logits = outputs.logits  # (batch_size, num_classes, height, width)\n",
    "            \n",
    "            # 레이블 크기 맞춤\n",
    "            output_size = logits.shape[-2:]\n",
    "            resized_targets = F.interpolate(\n",
    "                targets.unsqueeze(1).float(),\n",
    "                size=output_size,\n",
    "                mode=\"nearest\"\n",
    "            ).squeeze(1).long()\n",
    "            \n",
    "            # 손실 계산\n",
    "            ce_loss = ce_loss_fn(logits, resized_targets)\n",
    "            targets_one_hot = F.one_hot(resized_targets, num_classes=logits.shape[1]).permute(0, 3, 1, 2).float()\n",
    "            iou_loss = iou_loss_fn(logits, targets_one_hot)\n",
    "            total_loss = 0.8 * ce_loss + 0.2 * iou_loss\n",
    "\n",
    "            # IoU 계산\n",
    "            preds = logits.argmax(dim=1)\n",
    "            iou = metric.compute(\n",
    "                predictions=preds.detach().cpu().numpy(),\n",
    "                references=resized_targets.detach().cpu().numpy(),\n",
    "                num_labels=2,\n",
    "                ignore_index=None\n",
    "            )[\"mean_iou\"]\n",
    "\n",
    "            # 손실 및 IoU 누적\n",
    "            test_loss += total_loss.item()\n",
    "            test_iou += iou\n",
    "\n",
    "            test_progress_bar.set_postfix({\"Batch Loss\": total_loss.item(), \"Batch mIoU\": iou})\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    avg_test_iou = test_iou / len(test_dataloader)\n",
    "\n",
    "    print(f\"\\nAverage Test Loss: {avg_test_loss:.4f}, Average Test mIoU: {avg_test_iou:.4f}\")\n",
    "    return avg_test_loss, avg_test_iou\n",
    "\n",
    "# 경로 설정\n",
    "pth_path = \"/WD/improve/model/best_model_focal_iou2.pth\"\n",
    "\n",
    "# 모델 불러오기\n",
    "model = load_trained_model(pth_path, device)\n",
    "\n",
    "# 테스트 실행\n",
    "avg_test_loss, avg_test_iou = test_model(model, test_dataloader, device)\n",
    "print(f\"Final Test Loss: {avg_test_loss:.4f}, Final Test mIoU: {avg_test_iou:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_209320/1787250214.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path, map_location=device))  # 저장된 모델 가중치 불러오기\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 379/379 [00:56<00:00,  6.66it/s, Batch Loss=0.0593, Batch mIoU=0.644] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Test Loss: 0.0685, Average Test mIoU: 0.6926\n",
      "Final Test Loss: 0.0685, Final Test mIoU: 0.6926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import evaluate\n",
    "import logging\n",
    "\n",
    "# 로그 설정\n",
    "test_log_file = \"/WD/improve/log/test_log_focal_iou3.txt\"\n",
    "logging.basicConfig(filename=test_log_file, level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "\n",
    "# 손실 함수 정의\n",
    "focal_loss_fn = FocalLoss(alpha=0.15, gamma=2.5)  # Focal Loss\n",
    "iou_loss_fn = IoULoss()  # IoU Loss\n",
    "\n",
    "# IoU 메트릭\n",
    "metric = evaluate.load(\"mean_iou\")\n",
    "\n",
    "# 테스트 함수\n",
    "def test_model(model, test_dataloader, device):\n",
    "    test_loss = 0.0\n",
    "    test_iou = 0.0\n",
    "    model.eval()  # 평가 모드 설정\n",
    "\n",
    "    test_progress_bar = tqdm(test_dataloader, desc=\"Testing\", leave=True)\n",
    "\n",
    "    with torch.no_grad():  # 그래디언트 비활성화\n",
    "        for batch_idx, batch in enumerate(test_progress_bar):\n",
    "            # 데이터 준비\n",
    "            inputs = batch[\"pixel_values\"].to(device)\n",
    "            targets = batch[\"labels\"].to(device)\n",
    "\n",
    "            # 모델 출력\n",
    "            outputs = model(pixel_values=inputs)\n",
    "            logits = outputs.logits  # (batch_size, num_classes, height, width)\n",
    "\n",
    "            # 레이블 크기 조정\n",
    "            output_size = logits.shape[-2:]\n",
    "            resized_targets = F.interpolate(\n",
    "                targets.unsqueeze(1).float(),\n",
    "                size=output_size,\n",
    "                mode=\"nearest\"\n",
    "            ).squeeze(1).long()\n",
    "\n",
    "            # Focal Loss 계산\n",
    "            focal_loss = focal_loss_fn(logits, resized_targets)\n",
    "\n",
    "            # IoU Loss 계산\n",
    "            targets_one_hot = F.one_hot(resized_targets, num_classes=logits.shape[1]).permute(0, 3, 1, 2).float()\n",
    "            iou_loss = iou_loss_fn(logits, targets_one_hot)\n",
    "\n",
    "            # 손실 조합\n",
    "            total_loss = 0.7 * focal_loss + 0.3 * iou_loss\n",
    "\n",
    "            # IoU 계산\n",
    "            preds = logits.argmax(dim=1)\n",
    "            iou = metric.compute(\n",
    "                predictions=preds.detach().cpu().numpy(),\n",
    "                references=resized_targets.detach().cpu().numpy(),\n",
    "                num_labels=2,\n",
    "                ignore_index=None\n",
    "            )[\"mean_iou\"]\n",
    "\n",
    "            # 손실 및 IoU 누적\n",
    "            test_loss += total_loss.item()\n",
    "            test_iou += iou\n",
    "\n",
    "            # 로그 기록\n",
    "            logging.info(f\"Batch {batch_idx + 1}, Test Loss: {total_loss.item():.4f}, Test mIoU: {iou:.4f}\")\n",
    "            test_progress_bar.set_postfix({\"Batch Loss\": total_loss.item(), \"Batch mIoU\": iou})\n",
    "\n",
    "    # 평균 손실 및 IoU 계산\n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    avg_test_iou = test_iou / len(test_dataloader)\n",
    "\n",
    "    print(f\"\\nAverage Test Loss: {avg_test_loss:.4f}, Average Test mIoU: {avg_test_iou:.4f}\")\n",
    "    logging.info(f\"Average Test Loss: {avg_test_loss:.4f}, Average Test mIoU: {avg_test_iou:.4f}\")\n",
    "\n",
    "    return avg_test_loss, avg_test_iou\n",
    "\n",
    "\n",
    "# 모델 로드\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_model_path = \"/WD/improve/model/best_model_focal_iou3.pth\"\n",
    "\n",
    "# 모델 로드 및 초기화\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=device))  # 저장된 모델 가중치 불러오기\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 테스트 데이터 로드 (예시)\n",
    "# 테스트 데이터는 pixel_values와 labels를 포함해야 합니다.\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# 테스트 실행\n",
    "print(\"\\nStarting Test...\")\n",
    "avg_test_loss, avg_test_iou = test_model(model, test_dataloader, device)\n",
    "print(f\"Final Test Loss: {avg_test_loss:.4f}, Final Test mIoU: {avg_test_iou:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "025fc99e45774b97b82ced213c01b032": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0a456466197544ed9cb71bbe78763de1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "10e05f86b27849dc8074c5fc25349552": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecb3297ad6754f338c2a9b8dd3122d10",
      "placeholder": "​",
      "style": "IPY_MODEL_f38dc7f425f44db99ab0f9439af2c200",
      "value": " 7062/7062 [08:00&lt;00:00, 19.93 examples/s]"
     }
    },
    "154b195e88114d699a554b9907f449e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e972b8a74c74c01abc26ee061e71290",
      "placeholder": "​",
      "style": "IPY_MODEL_3c2c9dd3631244ab9a271a64e81568eb",
      "value": "config.json: 100%"
     }
    },
    "1bf83befc0a04dcb82df380df5daaf32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28beca68a34c4394836566f6329ce3e7",
      "placeholder": "​",
      "style": "IPY_MODEL_ba3c19d44c60496da0796b5ed6a94ecd",
      "value": "Downloading builder script: 100%"
     }
    },
    "1c3ad526f29d41b3ad110a3f7ff296d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f9986d3944346699f42e676d93f0ba7",
      "placeholder": "​",
      "style": "IPY_MODEL_daec601dd9ac4dac97c6b6b36e14cc4d",
      "value": " 1513/1513 [01:36&lt;00:00,  1.47s/ examples]"
     }
    },
    "1c3b93e8a78e4a7b8ac94ae30296308e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_969007622e424e70aaec1b9c5f240710",
       "IPY_MODEL_4a57af2bb2c4454ea9cf659f2a79c479",
       "IPY_MODEL_1c3ad526f29d41b3ad110a3f7ff296d8"
      ],
      "layout": "IPY_MODEL_3636cb4304d441f5b659adb92e69c2cb"
     }
    },
    "1ecbe482c6d640b8b1daa083630bedad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "222c73e3477247a2b45b25b39e40393f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28beca68a34c4394836566f6329ce3e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c3b7eeb87de4bf594acd1869a55ed99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32684a8be7d841efa056f8e54f2fa85f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "335284e6ffb848a9878d5f97a39530db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6ac457e0d0a745119ef9dfc9f7fa8033",
       "IPY_MODEL_3370ad79e9284faaab80a14f89b436b6",
       "IPY_MODEL_38a2a4e3d9d141508224b4af6f34a63b"
      ],
      "layout": "IPY_MODEL_6b9f590f97054c229146cf57c0a13b7d"
     }
    },
    "3370ad79e9284faaab80a14f89b436b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ecbe482c6d640b8b1daa083630bedad",
      "max": 1514,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3af1e3ce91514fd8aa3ef15ed8ec5357",
      "value": 1514
     }
    },
    "35fa7f2995c843b493ee30221444c469": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8df03259160442a3881a03256628070b",
      "placeholder": "​",
      "style": "IPY_MODEL_4108278ecc0949039bf2ad2a07e818c5",
      "value": "preprocessor_config.json: 100%"
     }
    },
    "36074d11187f480d91374bd5909e6abf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f090f09aa60944258733faa9b920972d",
      "max": 272,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7e8e8663c06f401abf70760c1fa3f658",
      "value": 272
     }
    },
    "3636cb4304d441f5b659adb92e69c2cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38a2a4e3d9d141508224b4af6f34a63b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_861e6d130f0c4820a5d4a9e0f6ffd0f2",
      "placeholder": "​",
      "style": "IPY_MODEL_7cc5770a80624e79bca25375a4cb58ef",
      "value": " 1514/1514 [01:35&lt;00:00,  1.48s/ examples]"
     }
    },
    "3af1e3ce91514fd8aa3ef15ed8ec5357": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3c2c9dd3631244ab9a271a64e81568eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f9986d3944346699f42e676d93f0ba7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4108278ecc0949039bf2ad2a07e818c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43cbe44496f0421db991b9c48bec99d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44a1ab5f4a114f42943e65c75bcf4436": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47efafcdb9a94c72bdd77605046836aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a4e9637ac124b23be83082c4ef5f1ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50a8cd8bc87c48bfae3d5b6236d03daf",
      "placeholder": "​",
      "style": "IPY_MODEL_5e2c5cf3736245649a2d0bc06be63607",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "4a57af2bb2c4454ea9cf659f2a79c479": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47efafcdb9a94c72bdd77605046836aa",
      "max": 1513,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_025fc99e45774b97b82ced213c01b032",
      "value": 1513
     }
    },
    "4e581a709f8b4bf29d0b84f5b13efa06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4ea31177b1f74daeba95a68e860c3180": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f5474e79d07413ebcf8845feda89d9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50a8cd8bc87c48bfae3d5b6236d03daf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d21ccdfc06d43bfb9f849edc5124574": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b8b7cf9d9674a538bf7b7f2e501b9a9",
      "max": 12929,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4e581a709f8b4bf29d0b84f5b13efa06",
      "value": 12929
     }
    },
    "5e2c5cf3736245649a2d0bc06be63607": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "639e8c2323974b39898a9bb225f33516": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a942eea34c2948e19e4c338fdb06f652",
      "max": 178586005,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b533220ff7b44898ae583fa70e8a035a",
      "value": 178586005
     }
    },
    "665211f882de423ca7dc4ba53fd89c6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "67235640d2c6420d9ad298c33e385e87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb75302fc037446bb479abe520479828",
      "max": 7062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_81b62805df294d8c9bc5b39813d54a8a",
      "value": 7062
     }
    },
    "6ac457e0d0a745119ef9dfc9f7fa8033": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43cbe44496f0421db991b9c48bec99d6",
      "placeholder": "​",
      "style": "IPY_MODEL_77f0a1d4f2bc427eaa16c46d2f4f51c2",
      "value": "Map: 100%"
     }
    },
    "6b8b7cf9d9674a538bf7b7f2e501b9a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b9f590f97054c229146cf57c0a13b7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7769650ce0114b9f908253017cfdb897": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32684a8be7d841efa056f8e54f2fa85f",
      "placeholder": "​",
      "style": "IPY_MODEL_980e4f7edd9b496a9e4c393867fb4b3c",
      "value": " 70.0k/70.0k [00:00&lt;00:00, 3.32MB/s]"
     }
    },
    "77f0a1d4f2bc427eaa16c46d2f4f51c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7cc5770a80624e79bca25375a4cb58ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e8e8663c06f401abf70760c1fa3f658": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "802bc2f9cbfa47cf92c2d8beb847a3b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81b62805df294d8c9bc5b39813d54a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "82f0bbb4e695440a88cf3ac11074157d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2fc32c3ccf142048dd1116980d1ac2b",
      "placeholder": "​",
      "style": "IPY_MODEL_0a456466197544ed9cb71bbe78763de1",
      "value": " 179M/179M [00:01&lt;00:00, 208MB/s]"
     }
    },
    "845435d09ca14506a784c56e4ae5a9f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "861e6d130f0c4820a5d4a9e0f6ffd0f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88a7668077984e799f6b82e77ff94b24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8df03259160442a3881a03256628070b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e972b8a74c74c01abc26ee061e71290": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f71ef865ae3418fb380da4f828ab4e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ea31177b1f74daeba95a68e860c3180",
      "max": 70045,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_665211f882de423ca7dc4ba53fd89c6d",
      "value": 70045
     }
    },
    "9110a3a1eae54e36a83a9fa575ef160b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_154b195e88114d699a554b9907f449e4",
       "IPY_MODEL_8f71ef865ae3418fb380da4f828ab4e1",
       "IPY_MODEL_7769650ce0114b9f908253017cfdb897"
      ],
      "layout": "IPY_MODEL_e85429c00e1148edbee139a34d11ef0f"
     }
    },
    "969007622e424e70aaec1b9c5f240710": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9accc47cdcd44f75a075258fc5627790",
      "placeholder": "​",
      "style": "IPY_MODEL_aa6807386f57472b9d5c401d987cd4c0",
      "value": "Map: 100%"
     }
    },
    "980e4f7edd9b496a9e4c393867fb4b3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9accc47cdcd44f75a075258fc5627790": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1f2351f45d248fba58199dd39c8c5cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fe9e4ca8c5694f85a691303145afb153",
       "IPY_MODEL_67235640d2c6420d9ad298c33e385e87",
       "IPY_MODEL_10e05f86b27849dc8074c5fc25349552"
      ],
      "layout": "IPY_MODEL_4f5474e79d07413ebcf8845feda89d9e"
     }
    },
    "a942eea34c2948e19e4c338fdb06f652": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa6807386f57472b9d5c401d987cd4c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0cf038df14447e9b795cbc2fb7034e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1bf83befc0a04dcb82df380df5daaf32",
       "IPY_MODEL_5d21ccdfc06d43bfb9f849edc5124574",
       "IPY_MODEL_b377c18083674d8f867508e2e15f3206"
      ],
      "layout": "IPY_MODEL_2c3b7eeb87de4bf594acd1869a55ed99"
     }
    },
    "b2fc32c3ccf142048dd1116980d1ac2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b377c18083674d8f867508e2e15f3206": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_222c73e3477247a2b45b25b39e40393f",
      "placeholder": "​",
      "style": "IPY_MODEL_f13320761ce04d88b2a42d3b26011850",
      "value": " 12.9k/12.9k [00:00&lt;00:00, 1.05MB/s]"
     }
    },
    "b533220ff7b44898ae583fa70e8a035a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ba3c19d44c60496da0796b5ed6a94ecd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb75302fc037446bb479abe520479828": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca5a7ed3e4d24c36bffcc91a14eca94f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88a7668077984e799f6b82e77ff94b24",
      "placeholder": "​",
      "style": "IPY_MODEL_edf5dd947bae4bc5967074996cfa62b3",
      "value": " 272/272 [00:00&lt;00:00, 22.4kB/s]"
     }
    },
    "daec601dd9ac4dac97c6b6b36e14cc4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e667c30f320e486baf10470fd48ab6a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e85429c00e1148edbee139a34d11ef0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecb3297ad6754f338c2a9b8dd3122d10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed44b86dcdd649abb088c12310e925b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4a4e9637ac124b23be83082c4ef5f1ce",
       "IPY_MODEL_639e8c2323974b39898a9bb225f33516",
       "IPY_MODEL_82f0bbb4e695440a88cf3ac11074157d"
      ],
      "layout": "IPY_MODEL_44a1ab5f4a114f42943e65c75bcf4436"
     }
    },
    "edf5dd947bae4bc5967074996cfa62b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f090f09aa60944258733faa9b920972d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f13320761ce04d88b2a42d3b26011850": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f38dc7f425f44db99ab0f9439af2c200": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe9e4ca8c5694f85a691303145afb153": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e667c30f320e486baf10470fd48ab6a9",
      "placeholder": "​",
      "style": "IPY_MODEL_845435d09ca14506a784c56e4ae5a9f3",
      "value": "Map: 100%"
     }
    },
    "ff8116cf52ba45299c1b62b7220d5ea1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_35fa7f2995c843b493ee30221444c469",
       "IPY_MODEL_36074d11187f480d91374bd5909e6abf",
       "IPY_MODEL_ca5a7ed3e4d24c36bffcc91a14eca94f"
      ],
      "layout": "IPY_MODEL_802bc2f9cbfa47cf92c2d8beb847a3b0"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
